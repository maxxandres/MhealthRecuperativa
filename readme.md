# 游닂 Documentaci칩n Completa del Proyecto HAR (Human Activity Recognition)

## 1. Visi칩n General
Este sistema utiliza Inteligencia Artificial para identificar actividades f칤sicas humanas (como caminar, correr, sentarse) bas치ndose en datos de sensores corporales. El proyecto implementa una arquitectura "Full-Stack" que va desde el procesamiento de datos crudos hasta una interfaz de usuario interactiva para el an치lisis.

### Arquitectura del Sistema
*   **Frontend (Vue.js):** Dashboard interactivo para cargar archivos, visualizar la l칤nea de tiempo de actividades y comparar datos sensor por sensor.
*   **Backend (FastAPI):** Servidor API que recibe los archivos de log, procesa los datos y ejecuta el modelo de IA.
*   **Pipeline de IA (Python/Scikit-Learn):** M칩dulo encargado del entrenamiento, extracci칩n de caracter칤sticas y exportaci칩n del modelo.

---

## 2. El "Coraz칩n" del Sistema: Procesamiento de Datos

El modelo no "ve" el movimiento como nosotros (video), lo "siente" a trav칠s de n칰meros provenientes de aceler칩metros, giroscopios y magnet칩metros.

### A. Sensores Utilizados (26 Canales)
Utilizamos el conjunto de datos **MHEALTH**. A diferencia de otros enfoques, nos centramos exclusivamente en el movimiento, descartando se침ales biom칠dicas como el ECG.

| Ubicaci칩n | Sensores | Canales |
| :--- | :--- | :--- |
| **Pecho** | Aceler칩metro (X,Y,Z) | 3 |
| **Tobillo Izq.** | Aceler칩metro, Giroscopio, Magnet칩metro (X,Y,Z) | 9 |
| **Brazo Der.** | Aceler칩metro, Giroscopio, Magnet칩metro (X,Y,Z) | 9 |
| **Calculados** | Magnitudes Vectoriales (Acel/Giro de cada parte) | 5 |
| **TOTAL** | | **26 Canales** |

### B. Ventaneo (Windowing)
El movimiento continuo se divide en peque침os fragmentos para ser analizados.
*   **Tama침o de Ventana:** 2.00 segundos (100 muestras a 50Hz).
*   **Solapamiento (Overlap):** 50% (Cada segundo se hace una nueva predicci칩n basada en los 칰ltimos 2 segundos).

### C. Ingenier칤a de Caracter칤sticas (Feature Engineering)
El modelo no recibe los 100 datos crudos por sensor (eso ser칤a demasiado ruido). En su lugar, resumimos cada ventana en **182 caracter칤sticas matem치ticas**.

Para **cada uno de los 26 canales**, calculamos 7 estad칤sticas:
1.  **Media (Mean):** Indica la direcci칩n promedio (gravedad/orientaci칩n).
2.  **Desviaci칩n Est치ndar (Std):** Indica la intensidad del movimiento.
3.  **M칤nimo:** Pico m치s bajo.
4.  **M치ximo:** Pico m치s alto.
5.  **Mediana:** Valor central (robusto a picos aislados).
6.  **Asimetr칤a (Skewness):** 쯃a se침al se inclina a un lado?
7.  **Energ칤a (FFT):** Ritmo y periodicidad del movimiento.

> **Matem치tica:** 26 canales 칑 7 estad칤sticas = **182 Features**.

### D. Normalizaci칩n
Antes de entrar al modelo, todos los datos pasan por un **StandardScaler**. Esto convierte los valores a "Z-Scores" (cu치ntas desviaciones est치ndar se alejan del promedio), permitiendo comparar peras con manzanas (ej. magnet칩metro vs giroscopio).

---

## 3. Entrenamiento del Modelo

El cerebro del sistema es un modelo de **Random Forest**, elegido por su robustez y capacidad para manejar m칰ltiples caracter칤sticas.

### Flujo de Entrenamiento (`har_mhealth_pipeline.py`)

1.  **Carga de Datos:** Se leen los archivos `.log` del dataset MHEALTH (sujetos 1-9 para entrenamiento).
2.  **Limpieza:** Se filtran las filas con etiqueta 0 (Null/Sin actividad).
3.  **Extracci칩n de Features:** Se aplica el proceso descrito arriba (ventaneo + c치lculo estad칤stico) para crear una tabla gigante de entrenamiento `(n_muestras, 182)`.
4.  **Escalado:** Se entrena el `StandardScaler` con los datos de entrenamiento y se guardan sus par치metros (`mean`, `scale`).
5.  **Entrenamiento:** Se entrena el clasificador `RandomForestClassifier` con 100 치rboles.
    *   *Nota:* Se usa `class_weight='balanced'` para evitar que el modelo se obsesione con las actividades m치s comunes.
6.  **Exportaci칩n:**
    *   El modelo se guarda en formato **ONNX** (`har_mhealth_model.onnx`) para ser universal y r치pido.
    *   Los par치metros de escalado se guardan en `scaler_params.json`.

---

## 4. Funcionamiento del An치lisis (Inferencia)

Cuando subes un archivo en el Frontend:

1.  **Frontend:** Env칤a el archivo `.log` al Backend.
2.  **Backend (`/predict/log`):**
    *   Lee el archivo y lo convierte a un DataFrame.
    *   Limpia nulos y calcula las magnitudes.
    *   **Importante:** Genera ventanas **Secuenciales** (cronol칩gicas) para poder reconstruir la l칤nea de tiempo.
    *   Extrae las 182 caracter칤sticas por ventana.
    *   **Normaliza** usando el `scaler_params.json` cargado previamente.
    *   Ejecuta el modelo ONNX para predecir la etiqueta.
3.  **Respuesta:** Devuelve un JSON con la l칤nea de tiempo: `[{inicio, fin, predicci칩n, realidad, features}, ...]`.
4.  **Frontend:**
    *   Dibuja las barras de colores.
    *   Calcula estad칤sticas (errores, duraci칩n, actividad dominante).
    *   Permite comparar los **Feature Vectors** de diferentes segmentos para depurar errores (ej. Magnet칩metro desviado).

---

## 5. Actividades Reconocidas

El sistema detecta 12 actividades espec칤ficas:
1.  De pie (Standing vs. Still)
2.  Sentado (Sitting)
3.  Acostado (Lying down)
4.  Caminando (Walking)
5.  Subiendo escaleras (Climbing stairs)
6.  Flexi칩n de cintura (Waist bends forward)
7.  Elevaci칩n de brazos (Frontal elevation of arms)
8.  Flexi칩n de rodillas (Knees bending/Crouching)
9.  Ciclismo (Cycling)
10. Trotar (Jogging)
11. Correr (Running)
12. Saltos (Jump front & back)
